{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.naive_bayes import MultinomialNB, GaussianNB\\nfrom sklearn.preprocessing import OneHotEncoder\\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold\\nfrom sklearn import metrics'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Datos import Datos\n",
    "from EstrategiaParticionado import *\n",
    "from Clasificador import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "'''from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn import metrics'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prueba de la clase Clasificacion, VecinosProximos<h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero se necesita obtener los datos en un formato correcto. Fijamos k en 5 y el tamaño del datostest en 20% de los datos totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = 'wdbc.data'\n",
    "\n",
    "dataset = Datos(archivo)\n",
    "k = 5\n",
    "p = 0.2\n",
    "seed = 0\n",
    "\n",
    "datos = dataset.datos\n",
    "# Utilizamos el diccionario para adaptar los datos\n",
    "for i in range(datos.shape[0]):\n",
    "    for j in range(datos.shape[1]):\n",
    "        if dataset.nominalAtributos[j]:\n",
    "            datos[i, j] = dataset.diccionario[j][datos[i, j]]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después, crear las particiones datostrain y datostest. En este caso de prueba utilizaremos validacionSimple con nEjecuciones = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = ValidacionSimple(p, 1)\n",
    "particiones = vs.creaParticiones(len(dataset.datos), seed=seed)\n",
    "\n",
    "datostrain = dataset.extraeDatos(particiones[0].indicesTrain)\n",
    "datostest = dataset.extraeDatos(particiones[0].indicesTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, se entrena el modelo utilizando el conjunto datostrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = ClasificadorVecinosProximos()\n",
    "cl.entrenamiento(datostrain, dataset.nominalAtributos, dataset.diccionario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y, por último se predice la clase para datostest utilizando los porcentajes obtenidos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = cl.clasifica(datostest, dataset.nominalAtributos, dataset.diccionario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos la precisión de nuestra predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "print(1-cl.error(datostest, prediccion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos obtenido aproximadamente un 84% de aciertos en este dataset y partición. Vamos a probar ahora los datos \"german.data\" haciendo las mismas operaciones que en el caso anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = 'pima-indians-diabetes.data'\n",
    "\n",
    "dataset = Datos(archivo)\n",
    "p = 0.3\n",
    "seed = 0\n",
    "k = 5\n",
    "\n",
    "datos = dataset.datos\n",
    "for i in range(datos.shape[0]):\n",
    "    for j in range(datos.shape[1]):\n",
    "        if dataset.nominalAtributos[j] or j == datos.shape[1] - 1:\n",
    "            datos[i, j] = dataset.diccionario[j][datos[i, j]]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = ValidacionSimple(p, 1)\n",
    "particiones = vs.creaParticiones(len(dataset.datos), seed=seed)\n",
    "\n",
    "datostrain = dataset.extraeDatos(particiones[0].indicesTrain)\n",
    "datostest = dataset.extraeDatos(particiones[0].indicesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = ClasificadorVecinosProximos()\n",
    "cl.entrenamiento(datostrain, dataset.nominalAtributos, dataset.diccionario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = cl.clasifica(datostest, dataset.nominalAtributos, dataset.diccionario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.991304347826087\n"
     ]
    }
   ],
   "source": [
    "print(1-cl.error(datostest, prediccion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo acierta en aproximadamente 92% de los casos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prueba de la clase Clasificacion, RegresionLogistica<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = 'pima-indians-diabetes.data'\n",
    "\n",
    "dataset = Datos(archivo)\n",
    "p = 0.2\n",
    "seed = 0\n",
    "k = 5\n",
    "\n",
    "datos = dataset.datos\n",
    "for i in range(datos.shape[0]):\n",
    "    for j in range(datos.shape[1]):\n",
    "        if dataset.nominalAtributos[j] or j == datos.shape[1] - 1:\n",
    "            datos[i, j] = dataset.diccionario[j][datos[i, j]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = ValidacionSimple(p, 1)\n",
    "particiones = vs.creaParticiones(len(dataset.datos), seed=seed)\n",
    "\n",
    "datostrain = dataset.extraeDatos(particiones[0].indicesTrain)\n",
    "datostest = dataset.extraeDatos(particiones[0].indicesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.14828835  0.2215905   0.49275787 -0.28978546 -0.29438254  0.40747351\n",
      "  0.35716305 -0.34120268  0.15634681]\n"
     ]
    }
   ],
   "source": [
    "cl = ClasificadorRegresionLogistica(alpha=1, n_epocas=10)\n",
    "cl.entrenamiento(datostrain, dataset.nominalAtributos, dataset.diccionario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 923.55003259  205.53688508 -337.51613518 -198.05823772   -6.95702967\n",
      " -395.5981417    26.1800336   -32.05131778 1241.15638032]\n",
      "[  7.    109.     80.     31.      0.     35.9     1.127  43.      1.   ]\n",
      "[  2.    128.     78.     37.    182.     43.3     1.224  31.      1.   ]\n",
      "[  5.    106.     82.     30.      0.     39.5     0.286  38.      0.   ]\n",
      "[  0.    117.      0.      0.      0.     33.8     0.932  44.      0.   ]\n",
      "[ 2.    92.    52.     0.     0.    30.1    0.141 22.     0.   ]\n",
      "[  7.    161.     86.      0.      0.     30.4     0.165  47.      1.   ]\n",
      "[ 5.    88.    66.    21.    23.    24.4    0.342 30.     0.   ]\n",
      "[  2.    155.     74.     17.     96.     26.6     0.433  27.      1.   ]\n",
      "[ 3.    99.    80.    11.    64.    19.3    0.284 30.     0.   ]\n",
      "[  9.   156.    86.     0.     0.    24.8    0.23  53.     1.  ]\n"
     ]
    }
   ],
   "source": [
    "prediccion = cl.clasifica(datostest, dataset.nominalAtributos, dataset.diccionario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5844155844155844\n"
     ]
    }
   ],
   "source": [
    "print(1-cl.error(datostest, prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hechas las pruebas, vamos a analizar la precisión media de los clasificadores. Primero sin la correción de Laplace. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Estrategia de particionado: Validación Simple</h5>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parámetros: nEjecuciones = 10, p = 0.2, archivo: 'tic-tac-toe.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = 'tic-tac-toe.data'\n",
    "\n",
    "dataset = Datos(archivo)\n",
    "\n",
    "datos = dataset.datos\n",
    "for i in range(datos.shape[0]):\n",
    "    for j in range(datos.shape[1]):\n",
    "        if dataset.nominalAtributos[j] or j == datos.shape[1] - 1:\n",
    "            datos[i, j] = dataset.diccionario[j][datos[i, j]]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.2\n",
    "nEjecuciones = 10\n",
    "seed = 0\n",
    "\n",
    "vs = ValidacionSimple(p, nEjecuciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = ClasificadorNaiveBayes()\n",
    "errores_vs_a1 = cl.validacion(vs, dataset, dataset.diccionario, dataset.nominalAtributos, alpha=0, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos la media y la desviación tipica de los errores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_vs_a1 = np.mean(errores_vs_a1)\n",
    "desv_vs_a1 = np.std(errores_vs_a1)\n",
    "\n",
    "print(media_vs_a1, desv_vs_a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos lo mismo para el otro conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = 'german.data'\n",
    "\n",
    "dataset = Datos(archivo)\n",
    "\n",
    "datos = dataset.datos\n",
    "for i in range(datos.shape[0]):\n",
    "    for j in range(datos.shape[1]):\n",
    "        if dataset.nominalAtributos[j] or j == datos.shape[1] - 1:\n",
    "            datos[i, j] = dataset.diccionario[j][datos[i, j]]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.2\n",
    "nEjecuciones = 10\n",
    "seed = 0\n",
    "\n",
    "vs = ValidacionSimple(p, nEjecuciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = ClasificadorNaiveBayes()\n",
    "errores_vs_a2 = cl.validacion(vs, dataset, dataset.diccionario, dataset.nominalAtributos, alpha=0, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_vs_a2 = np.mean(errores_vs_a2)\n",
    "desv_vs_a2 = np.std(errores_vs_a2)\n",
    "\n",
    "print(media_vs_a2, desv_vs_a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Estrategia de particionado: Validación Cruzada con k=10</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tic-tac-toe.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = 'tic-tac-toe.data'\n",
    "\n",
    "dataset = Datos(archivo)\n",
    "\n",
    "datos = dataset.datos\n",
    "for i in range(datos.shape[0]):\n",
    "    for j in range(datos.shape[1]):\n",
    "        if dataset.nominalAtributos[j] or j == datos.shape[1] - 1:\n",
    "            datos[i, j] = dataset.diccionario[j][datos[i, j]]\n",
    "\n",
    "k = 10\n",
    "vc = ValidacionCruzada(k)\n",
    "\n",
    "cl = ClasificadorNaiveBayes()\n",
    "errores_vc_a1 = cl.validacion(vc, dataset, dataset.diccionario, dataset.nominalAtributos, alpha = 0, seed=0)\n",
    "\n",
    "media_vc_a1 = np.mean(errores_vc_a1)\n",
    "desv_vc_a1 = np.std(errores_vc_a1)\n",
    "\n",
    "print(media_vc_a1, desv_vc_a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "german.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = 'german.data'\n",
    "\n",
    "dataset = Datos(archivo)\n",
    "\n",
    "datos = dataset.datos\n",
    "for i in range(datos.shape[0]):\n",
    "    for j in range(datos.shape[1]):\n",
    "        if dataset.nominalAtributos[j] or j == datos.shape[1] - 1:\n",
    "            datos[i, j] = dataset.diccionario[j][datos[i, j]]\n",
    "\n",
    "k = 10\n",
    "vc = ValidacionCruzada(k)\n",
    "\n",
    "cl = ClasificadorNaiveBayes()\n",
    "errores_vc_a2 = cl.validacion(vc, dataset, dataset.diccionario, dataset.nominalAtributos, alpha=0, seed=0)\n",
    "\n",
    "media_vc_a2 = np.mean(errores_vc_a2)\n",
    "desv_vc_a2 = np.std(errores_vc_a2)\n",
    "\n",
    "print(media_vc_a2, desv_vc_a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la corrección de Laplace (alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = 'tic-tac-toe.data'\n",
    "\n",
    "dataset = Datos(archivo)\n",
    "\n",
    "datos = dataset.datos\n",
    "for i in range(datos.shape[0]):\n",
    "    for j in range(datos.shape[1]):\n",
    "        if dataset.nominalAtributos[j] or j == datos.shape[1] - 1:\n",
    "            datos[i, j] = dataset.diccionario[j][datos[i, j]]\n",
    "\n",
    "k = 10\n",
    "p = 0.2\n",
    "nEjecuciones = 10\n",
    "vs = ValidacionSimple(p, nEjecuciones)\n",
    "vc = ValidacionCruzada(k)\n",
    "\n",
    "cl = ClasificadorNaiveBayes()\n",
    "errores_vc_a1_l = cl.validacion(vc, dataset, dataset.diccionario, dataset.nominalAtributos, alpha=1, seed=0)\n",
    "\n",
    "media_vc_a1_l = np.mean(errores_vc_a1_l)\n",
    "desv_vc_a1_l = np.std(errores_vc_a1_l)\n",
    "\n",
    "errores_vs_a1_l = cl.validacion(vs, dataset, dataset.diccionario, dataset.nominalAtributos, alpha=1, seed=0)\n",
    "\n",
    "media_vs_a1_l = np.mean(errores_vs_a1_l)\n",
    "desv_vs_a1_l = np.std(errores_vs_a1_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = 'german.data'\n",
    "\n",
    "dataset = Datos(archivo)\n",
    "\n",
    "datos = dataset.datos\n",
    "for i in range(datos.shape[0]):\n",
    "    for j in range(datos.shape[1]):\n",
    "        if dataset.nominalAtributos[j] or j == datos.shape[1] - 1:\n",
    "            datos[i, j] = dataset.diccionario[j][datos[i, j]]\n",
    "        \n",
    "k = 10\n",
    "p = 0.2\n",
    "nEjecuciones = 10\n",
    "\n",
    "vs = ValidacionSimple(p, nEjecuciones)\n",
    "vc = ValidacionCruzada(k)\n",
    "\n",
    "cl = ClasificadorNaiveBayes()\n",
    "errores_vc_a2_l = cl.validacion(vc, dataset, dataset.diccionario, dataset.nominalAtributos, alpha=1, seed=0)\n",
    "\n",
    "media_vc_a2_l = np.mean(errores_vc_a2_l)\n",
    "desv_vc_a2_l = np.std(errores_vc_a2_l)\n",
    "\n",
    "errores_vs_a2_l = cl.validacion(vs, dataset, dataset.diccionario, dataset.nominalAtributos, alpha=1, seed=0)\n",
    "\n",
    "media_vs_a2_l = np.mean(errores_vs_a2_l)\n",
    "desv_vs_a2_l = np.std(errores_vs_a2_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos todos los datos juntos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\ttic-tac-toe\\t\\tgerman')\n",
    "print('VS', '\\t(', round(media_vs_a1, 3), round(desv_vs_a1,3), ')\\t\\t(', round(media_vs_a2, 3), round(desv_vs_a2,3), ')')\n",
    "print('VC', '\\t(', round(media_vc_a1, 3), round(desv_vc_a1,3), ')\\t\\t(', round(media_vc_a2, 3), round(desv_vc_a2,3), ')')\n",
    "print('VS_L\\t(', round(media_vs_a1_l, 3), round(desv_vs_a1_l,3), ')\\t\\t(', round(media_vs_a2_l, 3), round(desv_vs_a2_l,3), ')')\n",
    "print('VC_L\\t(', round(media_vc_a1_l, 3), round(desv_vc_a1_l,3), ')\\t\\t(', round(media_vc_a2_l, 3), round(desv_vc_a2_l,3), ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se aprecia una gran diferencia entre validación simple y validación cruzada, de hecho las medias son prácticamente iguales, aunque la desviación tipica es algo mejor en el caso de validación simple. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y, respecto a la diferencia entre ambos archivos, parece que la predicción para german.data es algo más precisa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ambos casos, la desviación típica es pequeña, por tanto cabe esperar que el error cometido se encuentre cerca de la media calculada. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados con corrección de Laplace son iguales a los resultados sin esta. Esto se debe a que en el conjunto de antrenamiento no aparecen atributos tales que un valor de este no aparezca (aparezca 0 veces) dada una clase. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Scikit-Learn</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de Scikit-Learn, no hay una función que te permita tratar ciertos datosz como categóricos y ciertos datos del mismo dataset como continuos. Por tanto, utilizaremos MultinomialNB para el caso de datos categóricos (tic-tac-toe.data) y GaussianNB para el caso de que haya algún dato continuo (german.data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero empezamos con las pruebas de validación simple y con tic-tac-toe.data. Transformamos los datos al formato adecuado y realizamos la partición:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = 'tic-tac-toe.data'\n",
    "p = 0.2\n",
    "seed = 0\n",
    "\n",
    "dataset = Datos(archivo)\n",
    "\n",
    "datos = dataset.datos\n",
    "# Utilizamos el diccionario para adaptar los datos\n",
    "for i in range(datos.shape[0]):\n",
    "    for j in range(datos.shape[1]):\n",
    "        if dataset.nominalAtributos[j]:\n",
    "            datos[i, j] = dataset.diccionario[j][datos[i, j]]\n",
    "            \n",
    "X = datos[:, :-1]\n",
    "y = datos[:, -1]\n",
    "\n",
    "X = X.astype('int32')\n",
    "y = y.astype('int32')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=p, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos con la clasificación. Haremos una prueba sin Laplace (alpha=0) y otra con Laplace (alpha=1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb0 = MultinomialNB(alpha=0)\n",
    "\n",
    "mnb0.fit(X_train, y_train)\n",
    "\n",
    "y_pred0 = mnb0.predict(X_test)\n",
    "\n",
    "ac_tic_simple_0 = metrics.accuracy_score(y_test, y_pred0)\n",
    "print(\"Accuracy:\", ac_tic_simple_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb1 = MultinomialNB(alpha=1)\n",
    "\n",
    "mnb1.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = mnb1.predict(X_test)\n",
    "\n",
    "ac_tic_simple_1 = metrics.accuracy_score(y_test, y_pred1)\n",
    "print(\"Accuracy:\", ac_tic_simple_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que no hay diferencia entre haber utilizado Laplace y no haberlo utilizado. Puede que en este caso haya sido así, pero en general es buena idea utilizar Laplace, porque no se sabe como es el dataset, y podría ocurrir que alguna de las probabilidades condicionadas fuesen 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a realizar la misma prueba, pero esta vez utilizando validación cruzada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = 'tic-tac-toe.data'\n",
    "p = 0.2\n",
    "seed = 123\n",
    "k = 10\n",
    "\n",
    "dataset = Datos(archivo)\n",
    "\n",
    "datos = dataset.datos\n",
    "# Utilizamos el diccionario para adaptar los datos\n",
    "for i in range(datos.shape[0]):\n",
    "    for j in range(datos.shape[1]):\n",
    "        if dataset.nominalAtributos[j]:\n",
    "            datos[i, j] = dataset.diccionario[j][datos[i, j]]\n",
    "            \n",
    "X = datos[:, :-1]\n",
    "y = datos[:, -1]\n",
    "\n",
    "X = X.astype('int32')\n",
    "y = y.astype('int32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb2 = MultinomialNB(alpha=0)\n",
    "\n",
    "kf = KFold(n_splits=k, random_state=seed, shuffle=True)\n",
    "\n",
    "ac_tic_cruzada_0 = np.empty(k)\n",
    "\n",
    "cnt = 0\n",
    "for train, test in kf.split(X):\n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "    \n",
    "    mnb2.fit(X_train, y_train)\n",
    "\n",
    "    y_pred2 = mnb2.predict(X_test)\n",
    "\n",
    "    ac_tic_cruzada_0[cnt] = metrics.accuracy_score(y_test, y_pred2)\n",
    "\n",
    "    print(\"Accuracy:\", ac_tic_cruzada_0[cnt])\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb3 = MultinomialNB(alpha=1)\n",
    "\n",
    "kf = KFold(n_splits=k, random_state=seed, shuffle=True)\n",
    "\n",
    "ac_tic_cruzada_1 = np.empty(k)\n",
    "cnt = 0\n",
    "for train, test in kf.split(X):\n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "    \n",
    "    mnb3.fit(X_train, y_train)\n",
    "\n",
    "    y_pred3 = mnb3.predict(X_test)\n",
    "\n",
    "    ac_tic_cruzada_1[cnt] = metrics.accuracy_score(y_test, y_pred3)\n",
    "\n",
    "    print(\"Accuracy:\", ac_tic_cruzada_1[cnt])\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo, observamos que Laplace no influye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasamos a utilizar el dataset german.data y repetimos las mismas pruebas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = 'german.data'\n",
    "p = 0.2\n",
    "seed = 123\n",
    "\n",
    "dataset = Datos(archivo)\n",
    "\n",
    "datos = dataset.datos\n",
    "# Utilizamos el diccionario para adaptar los datos\n",
    "for i in range(datos.shape[0]):\n",
    "    for j in range(datos.shape[1]):\n",
    "        if dataset.nominalAtributos[j]:\n",
    "            datos[i, j] = dataset.diccionario[j][datos[i, j]]\n",
    "            \n",
    "X = datos[:, :-1]\n",
    "y = datos[:, -1]\n",
    "\n",
    "X = X.astype('int32')\n",
    "y = y.astype('int32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=p, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb0 = GaussianNB()\n",
    "\n",
    "gnb0.fit(X_train, y_train)\n",
    "\n",
    "y_pred4 = gnb0.predict(X_test)\n",
    "ac_german_simple = metrics.accuracy_score(y_test, y_pred4) \n",
    "print(\"Accuracy:\", ac_german_simple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb1 = GaussianNB()\n",
    "\n",
    "kf = KFold(n_splits=k, random_state=seed, shuffle=True)\n",
    "\n",
    "ac_german_cruzada = np.empty(k)\n",
    "cnt = 0\n",
    "\n",
    "for train, test in kf.split(X):\n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "    \n",
    "    gnb1.fit(X_train, y_train)\n",
    "\n",
    "    y_pred5 = gnb1.predict(X_test)\n",
    "    \n",
    "    ac_german_cruzada[cnt] = metrics.accuracy_score(y_test, y_pred5)\n",
    "\n",
    "    print(\"Accuracy:\", ac_german_cruzada[cnt])\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizamos todos los resultados obtenidos y los comparamos con nuestra implementación. Como los resultados con y sin Laplace son iguales en el caso de Scikit, ignoraremos Laplace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\ttic-tac-toe scikit\\ttic-tac-toe propio\\tgerman scikit\\t\\tgerman propio')\n",
    "print('VS\\t(', round(1-ac_tic_simple_0, 3), ')\\t\\t(', round(media_vs_a1, 3), round(desv_vs_a1,3), ')\\t\\t(', round(1-ac_german_simple, 3), ')\\t\\t(', round(media_vs_a2, 3), round(desv_vs_a2,3), ')')\n",
    "print('VC\\t(', round(np.mean(1-ac_tic_cruzada_0), 3), round(np.std(1-ac_tic_cruzada_0),3), ')\\t\\t(', round(media_vc_a1, 3), round(desv_vc_a1,3), ')\\t\\t(', round(np.mean(1-ac_german_cruzada), 3), round(np.std(1-ac_german_cruzada),3), ')\\t\\t(', round(media_vc_a2, 3), round(desv_vc_a2,3), ')')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, parece que nuestro estimador comete menos errores que el de Scikit para estos datos y esta semilla. Habría que realizar pruebas mas extensas para medir las calidades y comparar ambos esitimadores adecuadamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluación de hipótesis mediante Análisis ROC</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a realizar este análisis para cada tipo de validación y para cada dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.2\n",
    "seed = 0\n",
    "k = 10\n",
    "\n",
    "def get_ROC_data(conf_data, clases, ocurrencias_clases):\n",
    "    \n",
    "    matriz_conf = np.zeros((2, 2))\n",
    "    matriz_conf[0][0] = ocurrencias_clases[clases[1]]\n",
    "    matriz_conf[0][1] = ocurrencias_clases[clases[0]]\n",
    "    tpr = np.empty(len(datostest))\n",
    "    fpr = np.empty(len(datostest))\n",
    "\n",
    "    for i in range(len(conf_data)):\n",
    "        if conf_data[i][1] == clases[0]: # Dato negativo\n",
    "            matriz_conf[1][1] += 1 #TN\n",
    "            matriz_conf[0][1] -= 1 #FP\n",
    "\n",
    "        else: # Dato positivo\n",
    "            matriz_conf[1][0] += 1 #FN\n",
    "            matriz_conf[0][0] -= 1 #TP\n",
    "\n",
    "\n",
    "        tpr[i] = matriz_conf[0][0]/(matriz_conf[0][0]+matriz_conf[1][0])\n",
    "\n",
    "        fpr[i] = matriz_conf[0][1]/(matriz_conf[0][1]+matriz_conf[1][1])\n",
    "    \n",
    "    return tpr, fpr\n",
    "\n",
    "def get_matriz_conf(datostest, prediccion, clases):\n",
    "    matriz_conf = np.zeros((2, 2))\n",
    "    \n",
    "    for i in range(len(datostest)):\n",
    "        if prediccion[i] == clases[0]:\n",
    "            if datostest[i][-1] == clases[0]: # TN\n",
    "                matriz_conf[1][1] += 1\n",
    "            else: # FN \n",
    "                matriz_conf[1][0] += 1\n",
    "        else:\n",
    "            if datostest[i][-1] == clases[0]: # FP\n",
    "                matriz_conf[0][1] += 1\n",
    "            else: # TP\n",
    "                matriz_conf[0][0] += 1\n",
    "    \n",
    "    return matriz_conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>tic-tac-toe.data y validación simple</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = 'tic-tac-toe.data'\n",
    "\n",
    "dataset = Datos(archivo)\n",
    "\n",
    "datos = dataset.datos\n",
    "# Utilizamos el diccionario para adaptar los datos\n",
    "for i in range(datos.shape[0]):\n",
    "    for j in range(datos.shape[1]):\n",
    "        if dataset.nominalAtributos[j] or j==datos.shape[1]-1:\n",
    "            datos[i, j] = dataset.diccionario[j][datos[i, j]]\n",
    "\n",
    "\n",
    "vs = ValidacionSimple(p, 1)\n",
    "particiones = vs.creaParticiones(len(dataset.datos), seed=seed)\n",
    "\n",
    "datostrain = dataset.extraeDatos(particiones[0].indicesTrain)\n",
    "datostest = dataset.extraeDatos(particiones[0].indicesTest)\n",
    "datostest = np.array(datostest)\n",
    "\n",
    "clases, counts = np.unique(datostest[:, -1], return_counts=True)\n",
    "clases = sorted(clases)\n",
    "\n",
    "cl = ClasificadorNaiveBayes()\n",
    "cl.entrenamiento(datostrain, dataset.nominalAtributos, dataset.diccionario)\n",
    "\n",
    "prediccion = cl.clasifica(datostest, dataset.nominalAtributos, dataset.diccionario)\n",
    "\n",
    "conf_data = np.empty((len(prediccion), 2))\n",
    "for i in range(conf_data.shape[0]):\n",
    "    conf_data[i] = [cl.probabilidades[i][1], datostest[i][-1]]\n",
    "\n",
    "conf_data = sorted(conf_data, key=lambda x: x[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasamos a construir los datos necesarios para la curva ROC y a obtener la matriz de confusión. Como anotación, se asume que la clase negativa es la de menor valor y la positiva la de mayor valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_tic_simple, fpr_tic_simple = get_ROC_data(conf_data, clases, counts)\n",
    "matriz_conf_tic_simple = get_matriz_conf(datostest, prediccion, clases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Matriz de confusión tic-tac-toe.data validación simple\")\n",
    "print()\n",
    "print(\"\\t\\t\\t\\tReal\")\n",
    "print(\"\\t\\t  Positivo\\t\\tNegativo\")\n",
    "print(\"Estimado Positivo \", matriz_conf_tic_simple[0][0], \" \\t\\t \", matriz_conf_tic_simple[0][1])\n",
    "print(\"\\t Negativo \", matriz_conf_tic_simple[1][0], \" \\t\\t \", matriz_conf_tic_simple[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr_tic_simple, tpr_tic_simple)\n",
    "plt.title(\"Curva ROC tic-tac-toe.data validación simple\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>tic-tac-toe.data y validación cruzada con k=10</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = 'tic-tac-toe.data'\n",
    "\n",
    "dataset = Datos(archivo)\n",
    "\n",
    "datos = dataset.datos\n",
    "# Utilizamos el diccionario para adaptar los datos\n",
    "for i in range(datos.shape[0]):\n",
    "    for j in range(datos.shape[1]):\n",
    "        if dataset.nominalAtributos[j] or j==datos.shape[1]-1:\n",
    "            datos[i, j] = dataset.diccionario[j][datos[i, j]]\n",
    "\n",
    "\n",
    "vc = ValidacionCruzada(k)\n",
    "\n",
    "particiones = vc.creaParticiones(len(dataset.datos), seed=seed)\n",
    "matrices_conf_tic_cruzada = []\n",
    "tpr_tic_cruzada_lista = []\n",
    "fpr_tic_cruzada_lista = []\n",
    "\n",
    "for particion in particiones:\n",
    "    datostrain = dataset.extraeDatos(particion.indicesTrain)\n",
    "    datostest = dataset.extraeDatos(particion.indicesTest)\n",
    "    datostest = np.array(datostest)\n",
    "\n",
    "    clases, counts = np.unique(datostest[:, -1], return_counts=True)\n",
    "    clases = sorted(clases)\n",
    "\n",
    "\n",
    "    cl = ClasificadorNaiveBayes()\n",
    "    cl.entrenamiento(datostrain, dataset.nominalAtributos, dataset.diccionario)\n",
    "\n",
    "    prediccion = cl.clasifica(datostest, dataset.nominalAtributos, dataset.diccionario)\n",
    "    \n",
    "    conf_data = np.empty((len(prediccion), 2))\n",
    "    for i in range(conf_data.shape[0]):\n",
    "        conf_data[i] = [cl.probabilidades[i][1], datostest[i][-1]]\n",
    "\n",
    "    conf_data = sorted(conf_data, key=lambda x: x[0])\n",
    "    \n",
    "    tpr_tic_cruzada, fpr_tic_cruzada = get_ROC_data(conf_data, clases, counts)\n",
    "    matriz_conf_tic_cruzada = get_matriz_conf(datostest, prediccion, clases)\n",
    "    matrices_conf_tic_cruzada.append(matriz_conf_tic_cruzada)\n",
    "    tpr_tic_cruzada_lista.append(tpr_tic_cruzada)\n",
    "    fpr_tic_cruzada_lista.append(fpr_tic_cruzada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(k):\n",
    "    print(\"Matriz de confusión tic-tac-toe.data validación cruzada fold\", i+1)\n",
    "    print()\n",
    "    print(\"\\t\\t\\t\\tReal\")\n",
    "    print(\"\\t\\t  Positivo\\t\\tNegativo\")\n",
    "    print(\"Estimado Positivo \", matrices_conf_tic_cruzada[i][0][0], \" \\t\\t \", matrices_conf_tic_cruzada[i][0][1])\n",
    "    print(\"\\t Negativo \", matrices_conf_tic_cruzada[i][1][0], \" \\t\\t \", matrices_conf_tic_cruzada[i][1][1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "for i in range(k):\n",
    "    plt.plot(fpr_tic_cruzada_lista[i], tpr_tic_cruzada_lista[i], label=\"Fold \" + str(i))\n",
    "    \n",
    "plt.title(\"Curva ROC tic-tac-toe.data validación cruzada\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>german.data y validación simple</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = 'german.data'\n",
    "\n",
    "dataset = Datos(archivo)\n",
    "\n",
    "datos = dataset.datos\n",
    "# Utilizamos el diccionario para adaptar los datos\n",
    "for i in range(datos.shape[0]):\n",
    "    for j in range(datos.shape[1]):\n",
    "        if dataset.nominalAtributos[j] or j==datos.shape[1]-1:\n",
    "            datos[i, j] = dataset.diccionario[j][datos[i, j]]\n",
    "\n",
    "vs = ValidacionSimple(p, 1)\n",
    "particiones = vs.creaParticiones(len(dataset.datos), seed=seed)\n",
    "\n",
    "datostrain = dataset.extraeDatos(particiones[0].indicesTrain)\n",
    "datostest = dataset.extraeDatos(particiones[0].indicesTest)\n",
    "datostest = np.array(datostest)\n",
    "\n",
    "clases, counts = np.unique(datostest[:, -1], return_counts=True)\n",
    "clases = sorted(clases)\n",
    "\n",
    "cl = ClasificadorNaiveBayes()\n",
    "cl.entrenamiento(datostrain, dataset.nominalAtributos, dataset.diccionario)\n",
    "\n",
    "prediccion = cl.clasifica(datostest, dataset.nominalAtributos, dataset.diccionario)\n",
    "\n",
    "conf_data = np.empty((len(prediccion), 2))\n",
    "for i in range(conf_data.shape[0]):\n",
    "    conf_data[i] = [cl.probabilidades[i][1], datostest[i][-1]]\n",
    "\n",
    "conf_data = sorted(conf_data, key=lambda x: x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_german_simple, fpr_german_simple = get_ROC_data(conf_data, clases, counts)\n",
    "matriz_conf_german_simple = get_matriz_conf(datostest, prediccion, clases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Matriz de confusión german.data validación simple\")\n",
    "print()\n",
    "print(\"\\t\\t\\t\\tReal\")\n",
    "print(\"\\t\\t  Positivo\\t\\tNegativo\")\n",
    "print(\"Estimado Positivo \", matriz_conf_german_simple[0][0], \" \\t\\t \", matriz_conf_german_simple[0][1])\n",
    "print(\"\\t Negativo \", matriz_conf_german_simple[1][0], \" \\t\\t \", matriz_conf_german_simple[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr_german_simple, tpr_german_simple)\n",
    "plt.title(\"Curva ROC german.data validación simple\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>german.data y validación cruzada con k=10</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = 'german.data'\n",
    "\n",
    "dataset = Datos(archivo)\n",
    "\n",
    "datos = dataset.datos\n",
    "# Utilizamos el diccionario para adaptar los datos\n",
    "for i in range(datos.shape[0]):\n",
    "    for j in range(datos.shape[1]):\n",
    "        if dataset.nominalAtributos[j] or j==datos.shape[1]-1:\n",
    "            datos[i, j] = dataset.diccionario[j][datos[i, j]]\n",
    "\n",
    "\n",
    "vc = ValidacionCruzada(k)\n",
    "\n",
    "particiones = vc.creaParticiones(len(dataset.datos), seed=seed)\n",
    "matrices_conf_german_cruzada = []\n",
    "tpr_german_cruzada_lista = []\n",
    "fpr_german_cruzada_lista = []\n",
    "\n",
    "for particion in particiones:\n",
    "    datostrain = dataset.extraeDatos(particion.indicesTrain)\n",
    "    datostest = dataset.extraeDatos(particion.indicesTest)\n",
    "    datostest = np.array(datostest)\n",
    "\n",
    "    clases, counts = np.unique(datostest[:, -1], return_counts=True)\n",
    "    clases = sorted(clases)\n",
    "\n",
    "    cl = ClasificadorNaiveBayes()\n",
    "    cl.entrenamiento(datostrain, dataset.nominalAtributos, dataset.diccionario)\n",
    "\n",
    "    prediccion = cl.clasifica(datostest, dataset.nominalAtributos, dataset.diccionario)\n",
    "    \n",
    "    conf_data = np.empty((len(prediccion), 2))\n",
    "    for i in range(conf_data.shape[0]):\n",
    "        conf_data[i] = [cl.probabilidades[i][1], datostest[i][-1]]\n",
    "\n",
    "    conf_data = sorted(conf_data, key=lambda x: x[0])\n",
    "    \n",
    "    tpr_german_cruzada, fpr_german_cruzada = get_ROC_data(conf_data, clases, counts)\n",
    "    matriz_conf_german_cruzada = get_matriz_conf(datostest, prediccion, clases)\n",
    "    matrices_conf_german_cruzada.append(matriz_conf_german_cruzada)\n",
    "    tpr_german_cruzada_lista.append(tpr_german_cruzada)\n",
    "    fpr_german_cruzada_lista.append(fpr_german_cruzada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(k):\n",
    "    print(\"Matriz de confusión german.data validación cruzada fold\", i+1)\n",
    "    print()\n",
    "    print(\"\\t\\t\\t\\tReal\")\n",
    "    print(\"\\t\\t  Positivo\\t\\tNegativo\")\n",
    "    print(\"Estimado Positivo \", matrices_conf_german_cruzada[i][0][0], \" \\t\\t \", matrices_conf_german_cruzada[i][0][1])\n",
    "    print(\"\\t Negativo \", matrices_conf_german_cruzada[i][1][0], \" \\t\\t \", matrices_conf_german_cruzada[i][1][1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "for i in range(k):\n",
    "    plt.plot(fpr_german_cruzada_lista[i], tpr_german_cruzada_lista[i], label=\"Fold \" + str(i))\n",
    "    \n",
    "plt.title(\"Curva ROC german.data validación cruzada\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, vamos a calcular las áreas bajo las curvas ROC (AUC) para determinar la calidad de cada método:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AUC(fpr, tpr):\n",
    "\n",
    "    auc = 0\n",
    "    for i in range(len(tpr)-1):\n",
    "        auc += (fpr[i]-fpr[i+1])*tpr[i]\n",
    "    \n",
    "    auc += fpr[-1]*tpr[-1]\n",
    "        \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_tic_simple = AUC(fpr_tic_simple, tpr_tic_simple)\n",
    "auc_german_simple = AUC(fpr_german_simple, tpr_german_simple)\n",
    "\n",
    "auc_tic_cruzada_lista = []\n",
    "auc_german_cruzada_lista = []\n",
    "\n",
    "for i in range(len(fpr_tic_cruzada_lista)):\n",
    "    auc_tic_cruzada_lista.append(AUC(fpr_tic_cruzada_lista[i], tpr_tic_cruzada_lista[i]))\n",
    "    auc_german_cruzada_lista.append(AUC(fpr_german_cruzada_lista[i], tpr_german_cruzada_lista[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AUC tic-tac-toe.data VS:\", auc_tic_simple)\n",
    "\n",
    "print()\n",
    "for i in range(len(auc_tic_cruzada_lista)):\n",
    "    print(\"AUC tic-tac-toe.data VC Fold \" + str(i+1) + \":\" , auc_tic_cruzada_lista[i])\n",
    "\n",
    "print()\n",
    "print(\"AUC tic-tac-toe.data VC media: \", np.mean(auc_tic_cruzada_lista))\n",
    "print()\n",
    "print(\"AUC german.data VS:\", auc_german_simple)\n",
    "\n",
    "print()\n",
    "for i in range(len(auc_german_cruzada_lista)):\n",
    "    print(\"AUC german.data VC Fold \" + str(i+1) + \":\" , auc_german_cruzada_lista[i])\n",
    "    \n",
    "print()\n",
    "print(\"AUC german.data VC media: \", np.mean(auc_german_cruzada_lista))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cuanto al dataset tic-tac-toe.data, observamos unos mejores resultados en el caso de la validación cruzada. Sin embargo, en el caso de german.data hay mejores resultados con la validación simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Comentarios respecto a modificaciones en el diseño de clases <h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la clase EstrategiaParticionado, en la función creaParticiones cambiamos los parametros recomendados por un parametro n_datos, ya que en nuestra opinión es el único parámetro necesario para crear los conjuntos de indices. Con esto, deja de ser necesario pasar a la función una instancia de la clase Datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la hora de entrenamiento y clasificación, modificamos el conjunto de datos a un formado adecuado (cambiar los atributos nominales a un entero siguiendo el orden alfabético) utilizando el diccionario fuera de las funciones de la clase Clasificador. Esto nos parece más adecuado en cuanto a la separación las funcionalidades. \n",
    "\n",
    "También, tenemos el criterio de transformar la clase a su valor en el diccionario, sea el atributo nominal o numérico ya que la clase siempre es discreta. \n",
    "Esto permite simplificar el codigo gracias a la posible indexación array[valor1_clase].\n",
    "\n",
    "Asumimos la equivalencia entre nominalAtributos de la clase Datos y el parámetro atributosDiscretos que se pasa a las funciones de la clase Clasificador (con esta suposición resulta coherente transformar los valores de clase, atributo discreto, siempre a un entero entre 0 y n_valores). \n",
    "\n",
    "En la función clasifica añadimos el atributo alpha, el parámetro de la corrección de Laplace. \n",
    "\n",
    "Por último, cambiamos los atributos que se pasan a la función validacion de la clase Clasificador añadiendo todos aquellos atributos necesarios para llamar a las funciones entrenamiento y clasifica. También, eliminamos el parametro clasificador llamando a la función validación como instancia_clasificador.validacion(...)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
